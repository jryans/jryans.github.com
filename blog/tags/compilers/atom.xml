<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Compilers on J. Ryan Stinnett</title>
    <link>https://convolv.es/blog/tags/compilers/</link>
    <description>Recent content in Compilers on J. Ryan Stinnett</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Sat, 17 Aug 2024 22:27:06 +0100</lastBuildDate><atom:link href="https://convolv.es/blog/tags/compilers/atom.xml" rel="self" type="application/rss+xml" />
    <item xml:base="https://convolv.es/blog/2024/08/17/clang-ir-opt-level/">
      <title>Optimisation-dependent IR decisions in Clang</title>
      <link>https://convolv.es/blog/2024/08/17/clang-ir-opt-level/</link>
      <pubDate>Sat, 17 Aug 2024 22:27:06 +0100</pubDate>
      
      <guid>https://convolv.es/blog/2024/08/17/clang-ir-opt-level/</guid>
      <description>I used to naively assume that Clang always handed off the same IR to the LLVM optimisation pipeline regardless of optimisation level. In an attempt to gain a bit more understanding into exactly what kinds of decisions depend on optimisation level in Clang, I surveyed the IR emission code paths.</description>
      <content:encoded><![CDATA[<p>I used to naively assume that Clang always handed off &ldquo;basically&rdquo; the same IR to
the LLVM optimisation pipeline regardless of optimisation level. I was at least
aware of the <code>optnone</code> attribute set on functions when compiling at <code>-O0</code>, but
I&rsquo;ve slowly started to notice there are more divergences than just that.</p>
<h2 id="survey">Survey</h2>
<p>In an attempt to gain a bit more understanding into exactly what kinds of
decisions depend on optimisation level in Clang, I surveyed the <a href="https://github.com/search?q=repo%3Allvm%2Fllvm-project+path%3A%2F%5Eclang%5C%2Flib%5C%2FCodeGen%5C%2F%2F+OptimizationLevel&amp;type=code">IR emission
code
paths</a>.
I examined Clang source at commit <code>7c4c72b52038810a8997938a2b3485363cd6be3a</code>
(2024-08).</p>
<p>I ignored decisions related to specialised language specifics (Objective-C, ARC,
HLSL, OpenMP) and ABI details.</p>
<ul>
<li>When optimisation is disabled
<ul>
<li><a href="https://github.com/llvm/llvm-project/blob/997e5e870337e4a25b82be5b01e8f7675c350070/clang/lib/CodeGen/CGBlocks.cpp#L1503-L1513">Add <code>block.addr</code> stack slot to help debugger</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/1b8ab2f08998d3220e5d95003d47bb3d7cac966b/clang/lib/CodeGen/CGCXX.cpp#L38-L41">Keep destructor distinct from base class destructor to help debugger</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L1746-L1751">Keep switch case with just <code>break</code> as separate block to help debugger</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/d179acd0484bac30c5ebbbed4d29a4734d92ac93/clang/lib/CodeGen/CodeGenFunction.cpp#L1581-L1582">Add trap call for unreachable blocks</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CodeGenModule.cpp#L2485-L2488">Add <code>optnone</code> function attribute</a></li>
</ul>
</li>
<li>When optimisation is enabled
<ul>
<li><a href="https://github.com/llvm/llvm-project/blob/e91e0f52895e2b23bd690a86dbaafd979e027d29/clang/lib/CodeGen/CGBuiltin.cpp#L2585-L2587">Check if <code>errno</code> is disabled</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/e91e0f52895e2b23bd690a86dbaafd979e027d29/clang/lib/CodeGen/CGBuiltin.cpp#L3366-L3370">Pass <code>__builtin_expect</code> along via <code>llvm.expect</code></a> (<a href="https://github.com/llvm/llvm-project/blob/e91e0f52895e2b23bd690a86dbaafd979e027d29/clang/lib/CodeGen/CGBuiltin.cpp#L3392-L3396">2</a>)</li>
<li><a href="https://github.com/llvm/llvm-project/blob/4497ec293a6e745be817dc88027169bd5e4f7246/clang/lib/CodeGen/CGClass.cpp#L1309-L1312">Add various virtual table invariants and assumptions</a> (more in same file)</li>
<li><a href="https://github.com/llvm/llvm-project/blob/2f8f58dd17a11934e8c8ec212b6474f76fb18e61/clang/lib/CodeGen/CGDecl.cpp#L1008-L1009">Split constant struct / array stores into sequence for each field</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/07f8a65d09608d67bfd6adbd62bb0999c7363456/clang/lib/CodeGen/CGDeclCXX.cpp#L158-L160">Add various variable invariants</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGExpr.cpp#L2010-L2015">Add load range metadata</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGExpr.cpp#L2240-L2244">Add matrix index assumptions</a> (<a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGExpr.cpp#L2403-L2407">2</a>, <a href="https://github.com/llvm/llvm-project/blob/e108853ac8fad27ff22be9303c87d90bcdf0ef53/clang/lib/CodeGen/CGExprScalar.cpp#L2005-L2006">3</a>)</li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGExpr.cpp#L3842-L3850">Collapse trap calls</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/3ad31e12ccfc7db25f3cbedc4ee966e7099ac78f/clang/lib/CodeGen/CGExprCXX.cpp#L2277-L2280">Add exact dynamic casts</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92fc1eb0c1ae3813f2ac9208e2c74207aae9d23f/clang/lib/CodeGen/CGLoopInfo.cpp#L822-L828">Add loop unrolling metadata</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L870-L872">Add condition likelihood</a> (<a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L1049-L1051">2</a>, <a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L1264-L1266">3</a>, <a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L1367-L1369">4</a>, <a href="https://github.com/llvm/llvm-project/blob/d179acd0484bac30c5ebbbed4d29a4734d92ac93/clang/lib/CodeGen/CodeGenFunction.cpp#L3037-L3040">5</a>)</li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L2212-L2215">Track condition likelihood</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CGStmt.cpp#L2264-L2271">Pass <code>__builtin_unpredictable</code> along via metadata</a> (<a href="https://github.com/llvm/llvm-project/blob/d179acd0484bac30c5ebbbed4d29a4734d92ac93/clang/lib/CodeGen/CodeGenFunction.cpp#L2039-L2045">2</a>)</li>
<li><a href="https://github.com/llvm/llvm-project/blob/d179acd0484bac30c5ebbbed4d29a4734d92ac93/clang/lib/CodeGen/CodeGenFunction.cpp#L73-L74">Add lifetime markers</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CodeGenModule.cpp#L402-L406">Add type-based alias analysis (TBAA) metadata</a> (<a href="https://github.com/llvm/llvm-project/blob/123c036bd361de9ed6baa0090e5942105764e8db/clang/lib/CodeGen/CodeGenTBAA.cpp#L277-L279">2</a>, <a href="https://github.com/llvm/llvm-project/blob/123c036bd361de9ed6baa0090e5942105764e8db/clang/lib/CodeGen/CodeGenTBAA.cpp#L407-L408">3</a>)</li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CodeGenModule.cpp#L1031-L1046">Add strict virtual table metadata</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CodeGenModule.cpp#L4048-L4049">Preserve function declarations</a></li>
<li><a href="https://github.com/llvm/llvm-project/blob/92aec5192ce752c984837a93227200b54faa8679/clang/lib/CodeGen/CodeGenModule.cpp#L4101-L4103">Add opportunistic virtual tables</a></li>
</ul>
</li>
</ul>
<h2 id="example">Example</h2>
<p>If you&rsquo;d like to explore the differences yourself, take a look at this <a href="https://godbolt.org/z/GrbohjcWa">Compiler
Explorer example</a>. The input source is not too
interesting (I&rsquo;ve grabbed a random slice of Git source files that I happened to
have on hand). The left IR view shows <code>-O0</code> and the right IR view shows <code>-O1</code>
with LLVM passes disabled. We can ask Clang to produce LLVM IR without sending
it through the LLVM optimisation pipeline by adding <code>-Xclang -disable-llvm-passes</code> (a useful tip for LLVM archaeology).</p>
<p><a href="https://godbolt.org/z/GrbohjcWa"><img loading="lazy" src="ce.png" alt="Compiler Explorer playground comparing O0 and O1 LLVM IR"  />
</a></p>
<p>After diffing the two outputs, there are two features that are only activated
when optimisation is enabled that appear to be responsible for most of the
differences in this example:</p>
<ul>
<li>Lifetime markers</li>
<li>Type-based alias analysis (TBAA) metadata</li>
</ul>
<p>Lifetime markers are especially interesting in this example, as Clang actually
reshapes control flow (adding several additional <code>cleanup</code> blocks) so that it
can insert these markers (which are calls to LLVM intrinsic functions
<code>llvm.lifetime.start/end</code>).</p>
]]></content:encoded>
    </item>
    
    <item xml:base="https://convolv.es/guides/lto/">
      <title>Link-time optimisation (LTO)</title>
      <link>https://convolv.es/guides/lto/</link>
      <pubDate>Wed, 08 Nov 2023 15:49:51 +0000</pubDate>
      
      <guid>https://convolv.es/guides/lto/</guid>
      <description>I recently started exploring link-time optimisation (LTO), which I used to think was just a single boolean choice in the compilation and linking workflow, and perhaps it was like that a while ago&amp;hellip; I&amp;rsquo;ve learned that these days, there are many different dimensions of LTO across compilers and linkers today and more variations are being proposed all the time.
In this &amp;ldquo;living guide&amp;rdquo;, I aim to cover the LTO-related features I have encountered thus far.</description>
      <content:encoded><![CDATA[<p>I recently started exploring link-time optimisation (LTO),
which I used to think was just a single boolean choice
in the compilation and linking workflow,
and perhaps it was like that a while ago&hellip;
I&rsquo;ve learned that these days,
there are many different dimensions of LTO across
compilers and linkers today and more variations
<a href="https://discourse.llvm.org/t/rfc-a-unified-lto-bitcode-frontend/61774">are</a>
<a href="https://discourse.llvm.org/t/rfc-ffat-lto-objects-support/63977">being</a>
<a href="https://discourse.llvm.org/t/rfc-integrated-distributed-thinlto/69641">proposed</a>
all the time.</p>
<p>In this &ldquo;living guide&rdquo;,
I aim to cover the LTO-related features I have encountered thus far.
I intend to keep updating this going forward
as I learn about new details in this space.
I am sure there are even more corners to cover,
so if you see something that should be added, corrected, etc.
please <a href="/contact">contact me</a>.</p>
<p>I am <em>not</em> aiming to provide specific recommendations here,
as there are many tradeoffs to consider
and different applications of LTO will weigh each of those differently.
Instead, I hope this is a broadly useful portrayal of the facts.</p>
<p>This guide focuses on common toolchains for languages like C, Rust, etc. which
typically use ahead-of-time (AOT) compilation and linking. Alternative
toolchains for these languages and common toolchains for other languages may use
other strategies like interpreting, JIT compilation, etc. Those other language
implementation strategies do not offer LTO-like features (that I know of), so
I have ignored them here.</p>
<p>I hope this guide is useful to experienced compiler users and compiler hackers
who may not have heard about the latest work yet. I also hope it&rsquo;s broadly
accessible to those who may be unfamiliar with LTO.</p>
<hr>
<h2 id="basics">Basics</h2>
<p>Normal (non-LTO) compilation compiles and optimises one file at a time.
LTO can optimise across all files at once.
The overall aim of LTO is better runtime performance through whole-program
analysis and cross-module optimisation.</p>
<p>Let&rsquo;s take a high-level look at the workflow of most AOT compile and link
toolchains. We&rsquo;ll start off with the &ldquo;default&rdquo; workflow without LTO.</p>
<p><img loading="lazy" src="default-workflow.svg" alt="Default compile and link workflow with several source files optimised
separately into object files containing machine code, then linked to create the
final output"  />
</p>
<p>In the default workflow without LTO, each unit of source code is compiled and
optimised separately to produce an object file with machine code for the target
architecture. Optimisations can only consider a single source unit at a time, so
all externally accessible symbols (functions and variables) must be preserved,
even if they will end up being unused in the final linked output. The linker
then combines these object files to produce the final output (executable or
library).</p>
<p>Now let&rsquo;s look at a workflow with LTO.</p>
<p><img loading="lazy" src="lto-workflow.svg" alt=""  />
</p>
<p>In the LTO setup, we still initially compile each source unit separately and
perform some amount of optimisation, but the output is different: instead of
machine code, the output of LTO compilation is an object file containing
the compiler&rsquo;s specific internal representation (IR) for that source unit.</p>
<p>The linking stage now performs a much more complex dance than it did before.
The IR produced from compiling each source unit is read and the compiler&rsquo;s
optimisation pipeline is invoked to analyse and transform the whole program (the
precise details of this varies with different LTO features, as we&rsquo;ll see later
in this guide). This whole program stage unlocks further optimisation
opportunities, as we can remove symbols that are unused outside the whole
program, inline functions from other source units, etc.</p>
<p>With those fundamentals out of the way, let&rsquo;s look at various features and
variants that toolchains offer to further tweak and customise this process.</p>
<h2 id="features-and-variants">Features and variants</h2>

<div class="callout">
  <div>⚠️</div>
	<div class="callout-inner">
    Some of the features found in the LTO space have &ldquo;marketing&rdquo; names which do not
communicate what they actually do on a technical level.
For some descriptions below, I have used my own terminology to avoid these
issues.
Each section also lists other names things are known by, in case you want to
search for more information.
  </div>
</div>

<h3 id="basic-lto">Basic LTO</h3>
<p>This is the simplest of the LTO modes and matches the workflow described above
in <a href="#basics">Basics</a>.
Each compilation task produces object files containing the compiler&rsquo;s internal
IR format.
The linking stage combines all compilation units into a single, large module.
Interprocedural analysis and optimisation is performed on a single thread.
With large code bases, this process is likely to consume lots of memory and take
a considerable amount of time.</p>
<p><img loading="lazy" src="lto-workflow.svg" alt=""  />
</p>
<p>In terms of compile-time performance,
the LLVM project <a href="https://blog.llvm.org/2016/06/thinlto-scalable-and-incremental-lto.html">has shown</a> that compilation and linking of
the Clang 3.9 codebase with basic LTO is ~5x the non-LTO time.
This extra work achieves an average run-time performance improvement of 2.86%.</p>
<p>This mode is also referred to as &ldquo;full LTO&rdquo;.</p>
<table>
<thead>
<tr>
<th>Toolchain</th>
<th>First available</th>
<th>Option</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clang</td>
<td>2.6 (2009)</td>
<td><code>-flto</code> or <code>-flto=full</code></td>
</tr>
<tr>
<td>GCC</td>
<td>4.5 (2010)</td>
<td><code>-flto -flto-partition=one</code></td>
</tr>
<tr>
<td>Rust</td>
<td>1.0 (2015)</td>
<td><code>-C lto</code></td>
</tr>
</tbody>
</table>
<h3 id="parallel-lto">Parallel LTO</h3>
<p>Toolchains have come up with a variety of related techniques to speed up the
the link-time work of LTO while preserving (most of) the run-time performance
gains. Instead of creating a single, massive module at link time, a much smaller
global index of functions likely to be inlined is computed. With that in hand,
each compilation unit can be processed in parallel at link time while still
benefiting from most of the same whole-program optimisations as <a href="#basic-lto">basic
LTO</a>.</p>
<p><img loading="lazy" src="parallel-lto-workflow.svg" alt=""  />
</p>
<p>Continuing with the same <a href="https://blog.llvm.org/2016/06/thinlto-scalable-and-incremental-lto.html">example data</a> based on building Clang 3.9,
LLVM&rsquo;s implementation of parallel LTO
achieves nearly all of the run-time performance improvement
as seen with basic LTO:
basic LTO reached a 2.86% improvement over non-LTO,
while parallel LTO achieved a 2.63% improvement over non-LTO.</p>
<p>The compilation time improves dramatically: instead of 5x non-LTO, it&rsquo;s now only
1.2x non-LTO, which is quite impressive.</p>
<p>The technical details of how each toolchain
implements parallel LTO vary somewhat.
LLVM-based toolchains (which includes Clang and Rust from our discussions here)
optimise different compilation units in parallel
and inlines across module boundaries,
but most other cross-modules optimisations are skipped.
GCC, on the other hand,
partitions (nearly) the same optimisation work
it would have done with one thread into a batch per thread.</p>
<p>This suggests that GCC&rsquo;s parallel LTO should be able to get closer than LLVM
in achieving the same run-time performance as with basic LTO
(our recurring dataset shows a 0.23% run-time delta between
LLVM&rsquo;s basic and parallel modes).
At the same time, LLVM&rsquo;s approach may be better able to handle
incremental changes in a single module of large program.
If you would like to see data comparing the two modes in GCC,
please let me know.</p>
<p>This mode is also referred to as &ldquo;thin LTO&rdquo;,
particularly in the LLVM ecosystem.
The &ldquo;thin&rdquo; concept on the LLVM side
refers to the fact that no IR is involved in the whole program analysis step.</p>
<table>
<thead>
<tr>
<th>Toolchain</th>
<th>First available</th>
<th>Option</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clang</td>
<td>3.9 (2016)</td>
<td><code>-flto=thin</code></td>
</tr>
<tr>
<td>GCC</td>
<td>4.6 (2011)</td>
<td><code>-flto=auto</code> or <code>-flto=&lt;threads&gt;</code></td>
</tr>
<tr>
<td>Rust</td>
<td>1.25 (2018)</td>
<td><code>-C lto=thin</code></td>
</tr>
</tbody>
</table>
<h3 id="lto-with-mode-selection-deferred-to-link-time">LTO with mode selection deferred to link time</h3>
<p>In some applications, it may be useful to support both the <a href="#basic-lto">basic</a>
and <a href="#parallel-lto">parallel</a> LTO modes. In this arrangement, the compiler IR
attached to each object file stores all the info it needs to run either LTO mode
at link time.</p>
<p>When it&rsquo;s time to link, you can then choose either of
the basic or parallel LTO modes via link-time compiler options
(for the toolchains mentioned here,
the program commonly referred to as just the &ldquo;compiler&rdquo;
is really the &ldquo;compiler driver&rdquo;
which in turn calls the other programs in the workflow,
such as the linker).</p>
<p>This variant is also referred to as &ldquo;unified LTO&rdquo;.</p>
<table>
<thead>
<tr>
<th>Toolchain</th>
<th>First available</th>
<th>Option</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clang</td>
<td>17 (2023)</td>
<td><code>-funified-lto</code></td>
</tr>
<tr>
<td>GCC</td>
<td>4.5 (2010)</td>
<td>supported by default</td>
</tr>
<tr>
<td>Rust</td>
<td>—</td>
<td>—</td>
</tr>
</tbody>
</table>
<h3 id="lto-enablement-decision-deferred-to-link-time">LTO enablement decision deferred to link time</h3>
<p>It may also be useful to push the choice of whether to use LTO at all down to
the linking step of the workflow. To support this use case, the compiler
combines <em>both</em> machine code <em>and</em> internal IR in the object files produced by
each compilation unit.</p>
<p>This variant is also referred to as &ldquo;fat LTO objects&rdquo;.</p>
<table>
<thead>
<tr>
<th>Toolchain</th>
<th>First available</th>
<th>Option</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clang</td>
<td>17 (2023)</td>
<td><code>-ffat-lto-objects</code></td>
</tr>
<tr>
<td>GCC</td>
<td>4.9 (2014)</td>
<td><code>-ffat-lto-objects</code></td>
</tr>
<tr>
<td>Rust</td>
<td>—</td>
<td>—</td>
</tr>
</tbody>
</table>
<h3 id="other-details">Other details</h3>
<p>There are a few other more advanced corners of LTO, including:</p>
<ul>
<li>Distributed build support</li>
<li>Symbol visibility</li>
<li>Linker caching</li>
</ul>
<p>If you&rsquo;re curious about any of these or other aspects, please
<a href="/contact">let me know</a>!
I plan to extend this guide to document additional bits of LTO
that others are interested in.</p>
<hr>
<h4 id="acknowledgements">Acknowledgements</h4>
<p>Thanks to
<a href="https://discourse.llvm.org/u/teresajohnson">Teresa Johnson</a>,
<a href="https://www.ucw.cz/~hubicka/">Jan Hubička</a>,
<a href="https://github.com/nmdis1999">Iti Shree</a>, and
<a href="https://tratt.net/laurie/">Laurence Tratt</a>
for feedback on earlier drafts.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
